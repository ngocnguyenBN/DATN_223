{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) 1727\n"
     ]
    }
   ],
   "source": [
    "segment_size = 100\n",
    "\n",
    "# 1727 rows\n",
    "data = pd.read_csv('../Dataset/STB.csv')\n",
    "\n",
    "# Calculate the number of segments in the dataset\n",
    "print(\"len(data)\", len(data))\n",
    "num_segments = int(len(data)/segment_size)\n",
    "# Đọc vào tập dữ liệu bị phân mảnh ngang\n",
    "data_chunks = []\n",
    "for i in range(num_segments):\n",
    "    chunk = pd.read_csv(f'../Dataset/STB.csv')\n",
    "    data_chunks.append(chunk)\n",
    "data = pd.concat(data_chunks, ignore_index=True)\n",
    "data['date'] = pd.to_datetime(data.trunc_time)\n",
    "# Áp dụng moving average với cửa sổ 5 và lưu vào cột 'ma_5'\n",
    "data['ma_5'] = data['close_price'].rolling(window=5,min_periods=1).mean()\n",
    "\n",
    "# Xóa bỏ các dòng có giá trị null do moving average\n",
    "data.dropna(inplace=True)\n",
    "# Chia tập dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "# train_data = data.sample(frac=0.8, random_state=42)\n",
    "# test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       trunc_time  close_price          ma_5\n",
      "0      2016-01-04        12600  12600.000000\n",
      "1      2016-01-05        12300  12450.000000\n",
      "2      2016-01-06        12800  12566.666667\n",
      "3      2016-01-07        12600  12575.000000\n",
      "4      2016-01-08        12600  12580.000000\n",
      "...           ...          ...           ...\n",
      "29354  2022-11-21        16700  16450.000000\n",
      "29355  2022-11-22        16900  16810.000000\n",
      "29356  2022-11-23        17500  17080.000000\n",
      "29357  2022-11-24        18200  17280.000000\n",
      "29358  2022-11-25        18900  17640.000000\n",
      "\n",
      "[29359 rows x 3 columns]\n",
      "Shape of close dataframe: (29359, 3)\n"
     ]
    }
   ],
   "source": [
    "closedf = data[['trunc_time', 'close_price', 'ma_5']]\n",
    "print(closedf)\n",
    "print(\"Shape of close dataframe:\", closedf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18039216]\n",
      " [0.17504456]\n",
      " [0.1792038 ]\n",
      " ...\n",
      " [0.34010695]\n",
      " [0.34723708]\n",
      " [0.3600713 ]] (29359, 1)\n",
      "[[0.18563923]\n",
      " [0.17513135]\n",
      " [0.19264448]\n",
      " ...\n",
      " [0.35726795]\n",
      " [0.38178634]\n",
      " [0.40630473]] (29359, 1)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "close_stock = closedf.copy()\n",
    "del closedf['trunc_time']\n",
    "\n",
    "X_data = copy.deepcopy(closedf)\n",
    "Y_data = copy.deepcopy(closedf)\n",
    "\n",
    "del X_data['close_price']\n",
    "del Y_data['ma_5']\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "X_data=scaler.fit_transform(np.array(X_data).reshape(-1,1))\n",
    "Y_data=scaler.fit_transform(np.array(Y_data).reshape(-1,1))\n",
    "\n",
    "print(X_data, X_data.shape)\n",
    "print(Y_data, Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_set):\n",
    "    training_size=int(len(data_set)*0.8)\n",
    "    # test_size=len(data_set)-training_size\n",
    "    train_data,test_data=data_set[0:training_size,:],data_set[training_size:len(data_set),:1]\n",
    "    print(\"train_data: \", train_data)\n",
    "    print(\"test_data: \", test_data)\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "# def create_dataset(dataset, time_step=1):\n",
    "#     dataX, dataY = [], []\n",
    "#     for i in range(len(dataset)-time_step-1):\n",
    "#         a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "#         dataX.append(a)\n",
    "#         dataY.append(dataset[i + time_step, 0])\n",
    "#     return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  [[0.18039216]\n",
      " [0.17504456]\n",
      " [0.1792038 ]\n",
      " ...\n",
      " [0.13333333]\n",
      " [0.13048128]\n",
      " [0.12905526]]\n",
      "test_data:  [[0.1315508 ]\n",
      " [0.13368984]\n",
      " [0.14438503]\n",
      " ...\n",
      " [0.34010695]\n",
      " [0.34723708]\n",
      " [0.3600713 ]]\n",
      "train_data:  [[0.18563923]\n",
      " [0.17513135]\n",
      " [0.19264448]\n",
      " ...\n",
      " [0.12434326]\n",
      " [0.13485114]\n",
      " [0.13660245]]\n",
      "test_data:  [[0.15236427]\n",
      " [0.15061296]\n",
      " [0.17688266]\n",
      " ...\n",
      " [0.35726795]\n",
      " [0.38178634]\n",
      " [0.40630473]]\n",
      "X_train:  [[0.18039216]\n",
      " [0.17504456]\n",
      " [0.1792038 ]\n",
      " ...\n",
      " [0.13333333]\n",
      " [0.13048128]\n",
      " [0.12905526]]\n",
      "y_train:  (23487, 1)\n",
      "X_test:  (5872, 1)\n",
      "y_test (5872, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "# time_step = 10\n",
    "# print(type(X_data))\n",
    "X_train, X_test = create_dataset(X_data)\n",
    "y_train, y_test = create_dataset(Y_data)\n",
    "\n",
    "print(\"X_train: \", X_train)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "# print(\"type(X_test)\",type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data prediction: (23487, 1)\n",
      "Test data prediction: (5872, 1)\n"
     ]
    }
   ],
   "source": [
    "# Lets Do the prediction \n",
    "\n",
    "RF_train_predict=regressor.predict(X_train)\n",
    "RF_test_predict=regressor.predict(X_test)\n",
    "# print(\"Train data prediction:\", train_predict)\n",
    "# # print(\"Test data prediction:\", test_predict)\n",
    "RF_train_predict = RF_train_predict.reshape(-1,1)\n",
    "RF_test_predict = RF_test_predict.reshape(-1,1)\n",
    "\n",
    "print(\"Train data prediction:\", RF_train_predict.shape)\n",
    "print(\"Test data prediction:\", RF_test_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform back to original form\n",
    "\n",
    "RF_train_predict = scaler.inverse_transform(RF_train_predict)\n",
    "RF_test_predict = scaler.inverse_transform(RF_test_predict)\n",
    "RF_original_ytrain = scaler.inverse_transform(y_train.reshape(-1,1)) \n",
    "RF_original_ytest = scaler.inverse_transform(y_test.reshape(-1,1)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data RMSE:  254.6644098039925\n",
      "Train data MSE:  64853.961620815826\n",
      "Test data MAE:  127.59435155725494\n",
      "-------------------------------------------------------------------------------------\n",
      "Test data RMSE:  259.4448249375263\n",
      "Test data MSE:  67311.61718686366\n",
      "Test data MAE:  125.75692693592477\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrices RMSE and MAE\n",
    "RF_RMSE_train = math.sqrt(mean_squared_error(RF_original_ytrain,RF_train_predict))\n",
    "RF_MSE_train = mean_squared_error(RF_original_ytrain,RF_train_predict)\n",
    "RF_MAE_train = mean_absolute_error(RF_original_ytrain,RF_train_predict)\n",
    "\n",
    "RF_RMSE_test = math.sqrt(mean_squared_error(RF_original_ytest,RF_test_predict))\n",
    "RF_MSE_test = mean_squared_error(RF_original_ytest,RF_test_predict)\n",
    "RF_MAE_test = mean_absolute_error(RF_original_ytest,RF_test_predict)\n",
    "\n",
    "print(\"Train data RMSE: \", RF_RMSE_train)\n",
    "print(\"Train data MSE: \", RF_MSE_train)\n",
    "print(\"Test data MAE: \", RF_MAE_train)\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Test data RMSE: \", RF_RMSE_test)\n",
    "print(\"Test data MSE: \", RF_MSE_test)\n",
    "print(\"Test data MAE: \", RF_MAE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data explained variance regression score: 0.998588488803217\n",
      "Test data explained variance regression score: 0.9987088606976442\n"
     ]
    }
   ],
   "source": [
    "RF_EV_train = explained_variance_score(RF_original_ytrain, RF_train_predict)\n",
    "RF_EV_test = explained_variance_score(RF_original_ytest, RF_test_predict)\n",
    "\n",
    "print(\"Train data explained variance regression score:\", RF_EV_train)\n",
    "print(\"Test data explained variance regression score:\", RF_EV_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data R2 score: 0.9985884882083852\n",
      "Test data R2 score: 0.9987088254562629\n"
     ]
    }
   ],
   "source": [
    "RF_r2_train = r2_score(RF_original_ytrain, RF_train_predict)\n",
    "RF_r2_test = r2_score(RF_original_ytest, RF_test_predict)\n",
    "\n",
    "print(\"Train data R2 score:\", RF_r2_train)\n",
    "print(\"Test data R2 score:\", RF_r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data MGD:  0.0003135106900672148\n",
      "Test data MGD:  0.00030481439659525066\n",
      "----------------------------------------------------------------------\n",
      "Train data MPD:  4.322533107734379\n",
      "Test data MPD:  4.3199627821215065\n"
     ]
    }
   ],
   "source": [
    "RF_MGD_train = mean_gamma_deviance(RF_original_ytrain, RF_train_predict)\n",
    "RF_MGD_test = mean_gamma_deviance(RF_original_ytest, RF_test_predict)\n",
    "RF_MPD_train = mean_poisson_deviance(RF_original_ytrain, RF_train_predict)\n",
    "RF_MPD_test = mean_poisson_deviance(RF_original_ytest, RF_test_predict)\n",
    "print(\"Train data MGD: \", RF_MGD_train)\n",
    "print(\"Test data MGD: \", RF_MGD_test)\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"Train data MPD: \", RF_MPD_train)\n",
    "print(\"Test data MPD: \",RF_MPD_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23487, 1)\n",
      "Train predicted data:  (29359, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (5872,1) into shape (5850,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19372\\1425510943.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtestPredictPlot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosedf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtestPredictPlot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtestPredictPlot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRF_train_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosedf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRF_test_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test predicted data: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestPredictPlot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (5872,1) into shape (5850,2)"
     ]
    }
   ],
   "source": [
    "# shift train predictions for plotting\n",
    "from itertools import cycle\n",
    "import plotly.express as px\n",
    "print(RF_train_predict.shape)\n",
    "\n",
    "look_back=time_step\n",
    "trainPredictPlot = np.empty_like(closedf)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(RF_train_predict)+look_back, :] = RF_train_predict\n",
    "print(\"Train predicted data: \", trainPredictPlot.shape)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(closedf)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(RF_train_predict)+(look_back*2)+1:len(closedf)-1, :] = RF_test_predict\n",
    "print(\"Test predicted data: \", testPredictPlot.shape)\n",
    "\n",
    "names = cycle(['Original close price','Train predicted close price','Test predicted close price'])\n",
    "\n",
    "\n",
    "plotdf = pd.DataFrame({'date': close_stock['trunc_time'],\n",
    "                       'original_close': close_stock['ma_5'],\n",
    "                      'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n",
    "                      'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n",
    "\n",
    "fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n",
    "                                          plotdf['test_predicted_close']],\n",
    "              labels={'value':'Stock price','date': 'Date'})\n",
    "fig.update_layout(title_text='Comparision between original close price vs predicted close price',\n",
    "                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\n",
    "fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
    "\n",
    "fig.update_xaxes(showgrid=False)\n",
    "fig.update_yaxes(showgrid=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
