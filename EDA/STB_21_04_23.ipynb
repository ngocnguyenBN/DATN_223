{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) 1727\n"
     ]
    }
   ],
   "source": [
    "segment_size = 100\n",
    "\n",
    "# 1727 rows\n",
    "data = pd.read_csv('../Dataset/STB.csv')\n",
    "\n",
    "# Calculate the number of segments in the dataset\n",
    "print(\"len(data)\", len(data))\n",
    "num_segments = int(len(data)/segment_size)\n",
    "# Đọc vào tập dữ liệu bị phân mảnh ngang\n",
    "data_chunks = []\n",
    "for i in range(num_segments):\n",
    "    chunk = pd.read_csv(f'../Dataset/STB.csv')\n",
    "    data_chunks.append(chunk)\n",
    "data = pd.concat(data_chunks, ignore_index=True)\n",
    "data['date'] = pd.to_datetime(data.trunc_time)\n",
    "# Áp dụng moving average với cửa sổ 5 và lưu vào cột 'ma_5'\n",
    "data['ma_5'] = data['close_price'].rolling(window=5,min_periods=1).mean()\n",
    "\n",
    "# Xóa bỏ các dòng có giá trị null do moving average\n",
    "data.dropna(inplace=True)\n",
    "# Chia tập dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "# train_data = data.sample(frac=0.8, random_state=42)\n",
    "# test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       trunc_time  close_price          ma_5\n",
      "0      2016-01-04        12600  12600.000000\n",
      "1      2016-01-05        12300  12450.000000\n",
      "2      2016-01-06        12800  12566.666667\n",
      "3      2016-01-07        12600  12575.000000\n",
      "4      2016-01-08        12600  12580.000000\n",
      "...           ...          ...           ...\n",
      "29354  2022-11-21        16700  16450.000000\n",
      "29355  2022-11-22        16900  16810.000000\n",
      "29356  2022-11-23        17500  17080.000000\n",
      "29357  2022-11-24        18200  17280.000000\n",
      "29358  2022-11-25        18900  17640.000000\n",
      "\n",
      "[29359 rows x 3 columns]\n",
      "Shape of close dataframe: (29359, 3)\n"
     ]
    }
   ],
   "source": [
    "closedf = data[['trunc_time','close_price','ma_5']]\n",
    "print(closedf)\n",
    "print(\"Shape of close dataframe:\", closedf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18039216]\n",
      " [0.17504456]\n",
      " [0.1792038 ]\n",
      " ...\n",
      " [0.34010695]\n",
      " [0.34723708]\n",
      " [0.3600713 ]] (29359, 1)\n",
      "[[0.18563923]\n",
      " [0.17513135]\n",
      " [0.19264448]\n",
      " ...\n",
      " [0.35726795]\n",
      " [0.38178634]\n",
      " [0.40630473]] (29359, 1)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "close_stock = closedf.copy()\n",
    "del closedf['trunc_time']\n",
    "\n",
    "X_data = copy.deepcopy(closedf)\n",
    "Y_data = copy.deepcopy(closedf)\n",
    "\n",
    "del X_data['close_price']\n",
    "del Y_data['ma_5']\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "X_data=scaler.fit_transform(np.array(X_data).reshape(-1,1))\n",
    "Y_data=scaler.fit_transform(np.array(Y_data).reshape(-1,1))\n",
    "\n",
    "print(X_data, X_data.shape)\n",
    "print(Y_data, Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_size=int(len(closedf)*0.8)\n",
    "# test_size=len(closedf)-training_size\n",
    "# train_data,test_data=closedf[0:training_size,:],closedf[training_size:len(closedf),:1]\n",
    "# print(\"train_data: \", train_data.shape)\n",
    "# print(\"test_data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "# def create_dataset(dataset, time_step=1):\n",
    "#     dataX, dataY = [], []\n",
    "#     for i in range(len(dataset)-time_step-1):\n",
    "#         a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "#         dataX.append(a)\n",
    "#         dataY.append(dataset[i + time_step, 0])\n",
    "#     return np.array(dataX), np.array(dataY)\n",
    "def create_dataset(data_set):\n",
    "    training_size=int(len(data_set)*0.8)\n",
    "    # test_size=len(data_set)-training_size\n",
    "    train_data,test_data=data_set[0:training_size,:],data_set[training_size:len(data_set),:1]\n",
    "    print(\"train_data: \", train_data)\n",
    "    print(\"test_data: \", test_data)\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:  [[0.18039216]\n",
      " [0.17504456]\n",
      " [0.1792038 ]\n",
      " ...\n",
      " [0.13333333]\n",
      " [0.13048128]\n",
      " [0.12905526]]\n",
      "test_data:  [[0.1315508 ]\n",
      " [0.13368984]\n",
      " [0.14438503]\n",
      " ...\n",
      " [0.34010695]\n",
      " [0.34723708]\n",
      " [0.3600713 ]]\n",
      "train_data:  [[0.18563923]\n",
      " [0.17513135]\n",
      " [0.19264448]\n",
      " ...\n",
      " [0.12434326]\n",
      " [0.13485114]\n",
      " [0.13660245]]\n",
      "test_data:  [[0.15236427]\n",
      " [0.15061296]\n",
      " [0.17688266]\n",
      " ...\n",
      " [0.35726795]\n",
      " [0.38178634]\n",
      " [0.40630473]]\n",
      "X_train:  [[0.18039216]\n",
      " [0.17504456]\n",
      " [0.1792038 ]\n",
      " ...\n",
      " [0.13333333]\n",
      " [0.13048128]\n",
      " [0.12905526]]\n",
      "y_train:  (23487, 1)\n",
      "X_test:  (5872, 1)\n",
      "y_test (5872, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "time_step = 10\n",
    "# print(type(X_data))\n",
    "X_train, X_test = create_dataset(X_data)\n",
    "y_train, y_test = create_dataset(Y_data)\n",
    "\n",
    "print(\"X_train: \", X_train)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "# print(\"type(X_test)\",type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-23 13:07:17,862]\u001b[0m A new study created in memory with name: no-name-53ea060b-bb06-4f0f-ab1f-bd97fd426226\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 13:07:24,020]\u001b[0m Trial 0 finished with value: 9.794384355581547e-05 and parameters: {'n_estimators': 254, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'auto', 'bootstrap': True, 'criterion': 'squared_error'}. Best is trial 0 with value: 9.794384355581547e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 13:45:07,113]\u001b[0m Trial 1 finished with value: 0.00011015529657856413 and parameters: {'n_estimators': 661, 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'auto', 'bootstrap': False, 'criterion': 'absolute_error'}. Best is trial 0 with value: 9.794384355581547e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 13:45:23,603]\u001b[0m Trial 2 finished with value: 0.00019037296487355742 and parameters: {'n_estimators': 321, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'squared_error'}. Best is trial 0 with value: 9.794384355581547e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 13:46:18,464]\u001b[0m Trial 3 finished with value: 0.00012422953960974136 and parameters: {'n_estimators': 638, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'auto', 'bootstrap': False, 'criterion': 'friedman_mse'}. Best is trial 0 with value: 9.794384355581547e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:10:03,724]\u001b[0m Trial 4 finished with value: 9.585927909302096e-05 and parameters: {'n_estimators': 933, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_features': 'log2', 'bootstrap': True, 'criterion': 'absolute_error'}. Best is trial 4 with value: 9.585927909302096e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:10:31,834]\u001b[0m Trial 5 finished with value: 9.566090903341189e-05 and parameters: {'n_estimators': 926, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'friedman_mse'}. Best is trial 5 with value: 9.566090903341189e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:10:33,013]\u001b[0m Trial 6 finished with value: 8.265488091717475e-05 and parameters: {'n_estimators': 42, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'auto', 'bootstrap': True, 'criterion': 'squared_error'}. Best is trial 6 with value: 8.265488091717475e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:10:47,997]\u001b[0m Trial 7 finished with value: 0.00022798955332552017 and parameters: {'n_estimators': 537, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'squared_error'}. Best is trial 6 with value: 8.265488091717475e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:11:07,226]\u001b[0m Trial 8 finished with value: 8.25845792771448e-05 and parameters: {'n_estimators': 531, 'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'friedman_mse'}. Best is trial 8 with value: 8.25845792771448e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:11:19,778]\u001b[0m Trial 9 finished with value: 0.0003088635133150874 and parameters: {'n_estimators': 696, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'auto', 'bootstrap': True, 'criterion': 'squared_error'}. Best is trial 8 with value: 8.25845792771448e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:11:41,671]\u001b[0m Trial 10 finished with value: 8.282137857802886e-05 and parameters: {'n_estimators': 385, 'max_depth': 26, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'poisson'}. Best is trial 8 with value: 8.25845792771448e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:11:42,637]\u001b[0m Trial 11 finished with value: 8.266042276831344e-05 and parameters: {'n_estimators': 35, 'max_depth': 31, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True, 'criterion': 'friedman_mse'}. Best is trial 8 with value: 8.25845792771448e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:11:52,627]\u001b[0m Trial 12 finished with value: 8.282137857802873e-05 and parameters: {'n_estimators': 148, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'poisson'}. Best is trial 8 with value: 8.25845792771448e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:12:06,522]\u001b[0m Trial 13 finished with value: 8.261884253183465e-05 and parameters: {'n_estimators': 457, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'auto', 'bootstrap': True, 'criterion': 'friedman_mse'}. Best is trial 8 with value: 8.25845792771448e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-04-23 14:12:25,050]\u001b[0m Trial 14 finished with value: 8.258457927714483e-05 and parameters: {'n_estimators': 484, 'max_depth': 21, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False, 'criterion': 'friedman_mse'}. Best is trial 8 with value: 8.25845792771448e-05.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna:  {'n_estimators': 531, 'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'friedman_mse'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(bootstrap=False, criterion=&#x27;friedman_mse&#x27;, max_depth=23,\n",
       "                      max_features=&#x27;sqrt&#x27;, min_samples_leaf=3,\n",
       "                      min_samples_split=8, n_estimators=531)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(bootstrap=False, criterion=&#x27;friedman_mse&#x27;, max_depth=23,\n",
       "                      max_features=&#x27;sqrt&#x27;, min_samples_leaf=3,\n",
       "                      min_samples_split=8, n_estimators=531)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='friedman_mse', max_depth=23,\n",
       "                      max_features='sqrt', min_samples_leaf=3,\n",
       "                      min_samples_split=8, n_estimators=531)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regressor = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "# regressor.fit(X_train, y_train)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "    criterion = trial.suggest_categorical('criterion', ['poisson', 'squared_error', 'absolute_error', 'friedman_mse'])\n",
    "    random_state = 42\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        criterion=criterion,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Use Optuna to optimize hyperparameters\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "best_params = study.best_params\n",
    "print(\"Optuna: \", best_params)\n",
    "\n",
    "regressor = RandomForestRegressor(**best_params)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data prediction: (23487, 1)\n",
      "Test data prediction: (5872, 1)\n"
     ]
    }
   ],
   "source": [
    "# Lets Do the prediction \n",
    "\n",
    "RF_train_predict=regressor.predict(X_train)\n",
    "RF_test_predict=regressor.predict(X_test)\n",
    "# print(\"Train data prediction:\", train_predict)\n",
    "# # print(\"Test data prediction:\", test_predict)\n",
    "RF_train_predict = RF_train_predict.reshape(-1,1)\n",
    "RF_test_predict = RF_test_predict.reshape(-1,1)\n",
    "\n",
    "print(\"Train data prediction:\", RF_train_predict.shape)\n",
    "print(\"Test data prediction:\", RF_test_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform back to original form\n",
    "\n",
    "RF_train_predict = scaler.inverse_transform(RF_train_predict)\n",
    "RF_test_predict = scaler.inverse_transform(RF_test_predict)\n",
    "RF_original_ytrain = scaler.inverse_transform(y_train.reshape(-1,1)) \n",
    "RF_original_ytest = scaler.inverse_transform(y_test.reshape(-1,1)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data RMSE:  254.63785142125946\n",
      "Train data MSE:  64840.43537643541\n",
      "Test data MAE:  127.61935020312761\n",
      "-------------------------------------------------------------------------------------\n",
      "Test data RMSE:  259.4511457485762\n",
      "Test data MSE:  67314.89703024893\n",
      "Test data MAE:  125.77442914674934\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrices RMSE and MAE\n",
    "RF_RMSE_train = math.sqrt(mean_squared_error(RF_original_ytrain,RF_train_predict))\n",
    "RF_MSE_train = mean_squared_error(RF_original_ytrain,RF_train_predict)\n",
    "RF_MAE_train = mean_absolute_error(RF_original_ytrain,RF_train_predict)\n",
    "\n",
    "RF_RMSE_test = math.sqrt(mean_squared_error(RF_original_ytest,RF_test_predict))\n",
    "RF_MSE_test = mean_squared_error(RF_original_ytest,RF_test_predict)\n",
    "RF_MAE_test = mean_absolute_error(RF_original_ytest,RF_test_predict)\n",
    "\n",
    "print(\"Train data RMSE: \", RF_RMSE_train)\n",
    "print(\"Train data MSE: \", RF_MSE_train)\n",
    "print(\"Test data MAE: \", RF_MAE_train)\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Test data RMSE: \", RF_RMSE_test)\n",
    "print(\"Test data MSE: \", RF_MSE_test)\n",
    "print(\"Test data MAE: \", RF_MAE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data explained variance regression score: 0.9985887825998605\n",
      "Test data explained variance regression score: 0.9987088078369664\n"
     ]
    }
   ],
   "source": [
    "RF_EV_train = explained_variance_score(RF_original_ytrain, RF_train_predict)\n",
    "RF_EV_test = explained_variance_score(RF_original_ytest, RF_test_predict)\n",
    "\n",
    "print(\"Train data explained variance regression score:\", RF_EV_train)\n",
    "print(\"Test data explained variance regression score:\", RF_EV_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data R2 score: 0.9985887825998605\n",
      "Test data R2 score: 0.9987087625421559\n"
     ]
    }
   ],
   "source": [
    "RF_r2_train = r2_score(RF_original_ytrain, RF_train_predict)\n",
    "RF_r2_test = r2_score(RF_original_ytest, RF_test_predict)\n",
    "\n",
    "print(\"Train data R2 score:\", RF_r2_train)\n",
    "print(\"Test data R2 score:\", RF_r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data MGD:  0.0003134675295040991\n",
      "Test data MGD:  0.0003048511810084298\n",
      "----------------------------------------------------------------------\n",
      "Train data MPD:  4.321812876581981\n",
      "Test data MPD:  4.32041649011323\n"
     ]
    }
   ],
   "source": [
    "RF_MGD_train = mean_gamma_deviance(RF_original_ytrain, RF_train_predict)\n",
    "RF_MGD_test = mean_gamma_deviance(RF_original_ytest, RF_test_predict)\n",
    "RF_MPD_train = mean_poisson_deviance(RF_original_ytrain, RF_train_predict)\n",
    "RF_MPD_test = mean_poisson_deviance(RF_original_ytest, RF_test_predict)\n",
    "print(\"Train data MGD: \", RF_MGD_train)\n",
    "print(\"Test data MGD: \", RF_MGD_test)\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"Train data MPD: \", RF_MPD_train)\n",
    "print(\"Test data MPD: \",RF_MPD_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23487, 1)\n",
      "(5872, 1)\n",
      "Train predicted data:  (29359, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (5872,1) into shape (5850,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ACER\\Desktop\\datn223\\DATN_223\\EDA\\STB_21_04_23.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ACER/Desktop/datn223/DATN_223/EDA/STB_21_04_23.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m testPredictPlot \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(closedf)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ACER/Desktop/datn223/DATN_223/EDA/STB_21_04_23.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m testPredictPlot[:, :] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ACER/Desktop/datn223/DATN_223/EDA/STB_21_04_23.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m testPredictPlot[\u001b[39mlen\u001b[39m(RF_train_predict)\u001b[39m+\u001b[39m(look_back\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:\u001b[39mlen\u001b[39m(closedf)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :] \u001b[39m=\u001b[39m RF_test_predict\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ACER/Desktop/datn223/DATN_223/EDA/STB_21_04_23.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest predicted data: \u001b[39m\u001b[39m\"\u001b[39m, testPredictPlot\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ACER/Desktop/datn223/DATN_223/EDA/STB_21_04_23.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m names \u001b[39m=\u001b[39m cycle([\u001b[39m'\u001b[39m\u001b[39mOriginal close price\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mTrain predicted close price\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mTest predicted close price\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (5872,1) into shape (5850,2)"
     ]
    }
   ],
   "source": [
    "# shift train predictions for plotting\n",
    "from itertools import cycle\n",
    "import plotly.express as px\n",
    "print(RF_train_predict.shape)\n",
    "print(RF_test_predict.shape)\n",
    "\n",
    "look_back=time_step\n",
    "trainPredictPlot = np.empty_like(closedf)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(RF_train_predict)+look_back, :] = RF_train_predict\n",
    "print(\"Train predicted data: \", trainPredictPlot.shape)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(closedf)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(RF_train_predict)+(look_back*2)+1:len(closedf)-1, :] = RF_test_predict\n",
    "print(\"Test predicted data: \", testPredictPlot.shape)\n",
    "\n",
    "names = cycle(['Original close price','Train predicted close price','Test predicted close price'])\n",
    "\n",
    "\n",
    "plotdf = pd.DataFrame({'date': close_stock['trunc_time'],\n",
    "                       'original_close': close_stock['ma_5'],\n",
    "                      'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n",
    "                      'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n",
    "\n",
    "fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n",
    "                                          plotdf['test_predicted_close']],\n",
    "              labels={'value':'Stock price','date': 'Date'})\n",
    "fig.update_layout(title_text='Comparision between original close price vs predicted close price',\n",
    "                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\n",
    "fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
    "\n",
    "fig.update_xaxes(showgrid=False)\n",
    "fig.update_yaxes(showgrid=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-23 11:12:59,252]\u001b[0m A new study created in memory with name: no-name-55042f78-35b4-40b1-b583-282cf1135922\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
